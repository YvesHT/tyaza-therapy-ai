<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TYAZA  Therapy AI</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * { scroll-behavior: smooth; }
        :root { 
            --primary: #8b5cf6; 
            --primary-dark: #7c3aed; 
            --secondary: #ec4899;
            --bg-dark: #0a0a0c;
            --bg-card: #151518;
        }
        
        body { 
            font-family: 'Outfit', system-ui, sans-serif; 
            background: var(--bg-dark); 
            color: #ececee; 
            overflow: hidden; 
        }
        
        /* Glass sidebar */
        .glass-sidebar { 
            background: rgba(14, 14, 18, 0.95); 
            backdrop-filter: blur(28px); 
            border-right: 1px solid rgba(255,255,255,0.06); 
        }
        
        /* Chat bubbles */
        .chat-bubble-user { 
            background: linear-gradient(145deg, #1f1f24, #1a1a1f); 
            border: 1px solid rgba(255,255,255,0.06); 
            border-radius: 26px 26px 4px 26px; 
            padding: 16px 24px; 
            max-width: 80%; 
            color: #f0f0f2; 
            line-height: 1.6;
            box-shadow: 0 4px 15px rgba(0,0,0,0.3);
            font-size: 16px;
        }
        
        .chat-bubble-ai { 
            background: linear-gradient(145deg, #151518, #131316); 
            border-radius: 26px 26px 26px 4px; 
            padding: 20px 28px; 
            border: 1px solid rgba(255,255,255,0.03); 
            width: 100%; 
            color: #e2e2e8; 
            line-height: 1.8; 
            font-size: 16px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.3);
        }
        
        /* AI Avatar with TYAZA logo and therapy theme */
        .ai-avatar { 
            background: linear-gradient(135deg, var(--primary), var(--secondary)); 
            border-radius: 16px; 
            width: 44px; 
            height: 44px; 
            box-shadow: 0 8px 20px rgba(139,92,246,0.3);
            position: relative;
            overflow: hidden;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 700;
            font-size: 20px;
            color: white;
            transition: all 0.3s;
        }
        
        .ai-avatar::after {
            content: 'T';
            text-shadow: 0 2px 5px rgba(0,0,0,0.3);
            animation: heartbeat 2s infinite;
        }
        
        @keyframes heartbeat {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }
        
        .ai-avatar.thinking {
            animation: pulse-glow 1.5s infinite;
        }
        
        @keyframes pulse-glow {
            0%, 100% { box-shadow: 0 8px 20px rgba(139,92,246,0.3); }
            50% { box-shadow: 0 8px 30px rgba(236,72,153,0.8); }
        }
        
        /* Professional scrollbar */
        .custom-scroll::-webkit-scrollbar { width: 6px; }
        .custom-scroll::-webkit-scrollbar-track { background: transparent; }
        .custom-scroll::-webkit-scrollbar-thumb { 
            background: rgba(139,92,246,0.3); 
            border-radius: 20px;
            transition: all 0.2s;
        }
        .custom-scroll::-webkit-scrollbar-thumb:hover { background: rgba(139,92,246,0.5); }
        
        /* History items */
        .history-item { 
            transition: all 0.2s; 
            border-left: 3px solid transparent;
            position: relative;
            padding: 12px;
            border-radius: 12px;
            margin-bottom: 4px;
        }
        
        .history-item:hover { 
            background: rgba(139,92,246,0.1); 
            border-left-color: var(--primary); 
        }
        
        .history-item.active {
            background: rgba(139,92,246,0.15);
            border-left-color: var(--secondary);
        }
        
        /* Typing animation */
        .typing-animation {
            display: inline-flex;
            gap: 6px;
            align-items: center;
            padding: 12px 16px;
        }
        
        .typing-animation span {
            width: 10px;
            height: 10px;
            background: var(--primary);
            border-radius: 50%;
            display: inline-block;
            animation: typingBounce 1.4s infinite ease-in-out;
        }
        
        .typing-animation span:nth-child(1) { animation-delay: 0s; }
        .typing-animation span:nth-child(2) { animation-delay: 0.2s; background: var(--secondary); }
        .typing-animation span:nth-child(3) { animation-delay: 0.4s; }
        
        @keyframes typingBounce {
            0%, 60%, 100% { transform: translateY(0); }
            30% { transform: translateY(-12px); }
        }
        
        /* Message enter animation */
        .message-enter {
            animation: fadeInUp 0.4s ease-out forwards;
            opacity: 0;
        }
        
        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        /* Typing cursor effect for AI response */
        .typing-cursor {
            display: inline-block;
            width: 2px;
            height: 1.2em;
            background: var(--primary);
            margin-left: 4px;
            animation: blink 1s infinite;
            vertical-align: middle;
        }
        
        @keyframes blink {
            0%, 50% { opacity: 1; }
            51%, 100% { opacity: 0; }
        }
        
        /* Scroll to bottom button */
        .scroll-bottom-btn {
            position: fixed;
            bottom: 100px;
            right: 30px;
            background: var(--bg-card);
            border: 1px solid var(--primary);
            border-radius: 30px;
            padding: 10px 18px;
            color: var(--primary);
            font-size: 13px;
            cursor: pointer;
            transition: all 0.2s;
            opacity: 0;
            pointer-events: none;
            z-index: 40;
            box-shadow: 0 4px 15px rgba(0,0,0,0.3);
        }
        
        .scroll-bottom-btn.visible {
            opacity: 1;
            pointer-events: all;
        }
        
        .scroll-bottom-btn:hover {
            background: var(--primary);
            color: white;
            transform: translateY(-2px);
        }
        
        /* Voice button with animations */
        .voice-btn { 
            transition: all 0.3s;
            position: relative;
        }
        
        .voice-btn:hover { transform: scale(1.05); }
        
        .voice-btn.listening { 
            background: #ef4444 !important; 
            animation: pulse-listening 1.5s infinite; 
            color: white !important;
        }
        
        @keyframes pulse-listening {
            0%, 100% { opacity: 1; box-shadow: 0 0 0 0 rgba(239,68,68,0.7); }
            50% { opacity: 0.7; box-shadow: 0 0 0 10px rgba(239,68,68,0); }
        }
        
        /* Wave animation for voice */
        .wave-animation {
            display: flex;
            gap: 3px;
            align-items: center;
            height: 24px;
        }
        
        .wave-animation span {
            width: 4px;
            height: 20px;
            background: var(--primary);
            border-radius: 4px;
            animation: wave 1s infinite ease-in-out;
        }
        
        .wave-animation span:nth-child(2) { animation-delay: 0.2s; height: 30px; background: var(--secondary); }
        .wave-animation span:nth-child(3) { animation-delay: 0.4s; height: 16px; }
        .wave-animation span:nth-child(4) { animation-delay: 0.3s; height: 24px; }
        .wave-animation span:nth-child(5) { animation-delay: 0.1s; height: 28px; }
        
        @keyframes wave {
            0%, 100% { transform: scaleY(0.5); }
            50% { transform: scaleY(1.2); }
        }
        
        /* Full screen AI response container */
        .ai-response-full {
            width: 100%;
            max-width: 100%;
            margin: 0;
            padding: 0;
        }
        
        /* Settings panel */
        .settings-panel { 
            background: rgba(21,21,24,0.8);
            border: 1px solid rgba(139,92,246,0.2); 
            border-radius: 20px; 
            padding: 16px; 
            margin-bottom: 16px;
            backdrop-filter: blur(10px);
        }
        
        /* Voice visualization */
        .voice-visualization {
            display: flex;
            gap: 4px;
            align-items: center;
            justify-content: center;
            height: 40px;
        }
        
        .voice-visualization.active span {
            animation: voiceWave 0.5s infinite alternate;
        }
        
        @keyframes voiceWave {
            from { height: 5px; }
            to { height: 30px; }
        }
        
        /* Comfortable spacing for therapy */
        .therapy-spacing {
            line-height: 1.8;
            letter-spacing: 0.01em;
        }
        
        /* Empathy highlight */
        .empathy-word {
            color: var(--secondary);
            font-weight: 500;
            transition: all 0.2s;
        }
    </style>
</head>
<body class="flex h-screen">

    <!-- SCROLL TO BOTTOM BUTTON -->
    <div id="scroll-bottom-btn" class="scroll-bottom-btn" onclick="scrollToBottom()">
        <span class="flex items-center gap-2">?? Scroll to latest</span>
    </div>

    <!-- SIDEBAR -->
    <aside class="w-80 glass-sidebar flex flex-col p-4 z-30 border-r border-white/5">
        <button onclick="startNewChat()" class="flex items-center gap-3 w-full py-4 px-4 rounded-2xl bg-gradient-to-r from-purple-600/20 to-pink-600/10 hover:from-purple-600/30 hover:to-pink-600/20 transition-all border border-white/[0.05] mb-6 group">
            <span class="text-xl text-purple-400 group-hover:scale-110 transition">+</span> 
            <span class="text-sm font-medium tracking-wide">New therapy session</span>
        </button>
        
        <!-- API Key Input -->
        <div class="settings-panel">
            <label class="text-xs text-gray-400 block mb-2">?? OpenRouter Key</label>
            <input type="password" id="api-key-input" placeholder="sk-or-v1-..." 
                   class="w-full bg-black/30 border border-purple-500/30 rounded-xl px-3 py-2.5 text-sm text-white placeholder-gray-600 focus:outline-none focus:border-purple-500">
            <p class="text-[10px] text-gray-600 mt-2">Get free key at <a href="https://openrouter.ai" target="_blank" class="text-purple-400 hover:text-pink-400">openrouter.ai</a></p>
        </div>
        
        <!-- Voice Settings with Wave Animation -->
        <div class="settings-panel">
            <label class="text-xs text-gray-400 block mb-3">?? Voice Therapy Settings</label>
            
            <button id="test-mic-btn" class="w-full mb-3 py-2.5 px-3 bg-purple-600/20 hover:bg-purple-600/30 rounded-xl text-sm text-purple-400 transition flex items-center justify-center gap-2">
                <span>??</span> Test Microphone
            </button>
            
            <div id="voice-wave" class="voice-visualization h-10 mb-3 hidden">
                <span class="w-1 bg-purple-500"></span>
                <span class="w-1 bg-pink-500"></span>
                <span class="w-1 bg-purple-500"></span>
                <span class="w-1 bg-pink-500"></span>
                <span class="w-1 bg-purple-500"></span>
            </div>
            
            <select id="voice-select" class="w-full bg-black/30 border border-purple-500/30 rounded-xl px-3 py-2.5 text-sm text-white mb-3">
                <option value="Google UK English Female">???? Warm Female (Therapy)</option>
                <option value="Google UK English Male">???? Calm Male (Therapy)</option>
                <option value="Google US English">???? Soothing US English</option>
                <option value="Microsoft David - English (United States)">???? Gentle David</option>
                <option value="Microsoft Zira - English (United States)">???? Comforting Zira</option>
            </select>
            
            <label class="flex items-center gap-2 text-xs text-gray-400 mb-2">
                <input type="checkbox" id="auto-tts" checked class="accent-purple-500"> Auto-speak (therapeutic voice)
            </label>
            
            <div class="mt-3 flex items-center gap-2 text-xs">
                <span class="w-2.5 h-2.5 rounded-full bg-gray-600" id="mic-led"></span>
                <span id="mic-status-text" class="text-gray-500">Ready for therapy session</span>
            </div>
        </div>
        
        <!-- Session History -->
        <div class="flex items-center justify-between px-2 mb-3">
            <div class="text-xs text-gray-400 font-semibold tracking-wider">?? PAST SESSIONS</div>
            <button id="clear-history-btn" class="text-xs text-gray-600 hover:text-pink-400 transition px-2 py-1">Clear</button>
        </div>
        
        <div class="flex-1 overflow-y-auto custom-scroll space-y-1 pr-1" id="history-list"></div>
        
        <div class="mt-4 pt-4 border-t border-white/5 text-xs text-gray-600 flex items-center justify-between px-2">
            <span class="flex items-center gap-2">TYAZA  Therapy AI <span class="w-2 h-2 rounded-full bg-purple-400/70 animate-pulse"></span></span>
            <span>v2.0</span>
        </div>
    </aside>

    <!-- MAIN CHAT - FULL SCREEN AI RESPONSES -->
    <main class="flex-1 flex flex-col relative">
        <div class="absolute top-0 left-0 right-0 h-20 bg-gradient-to-b from-[#0a0a0c] to-transparent z-10 pointer-events-none"></div>

        <!-- CHAT VIEWPORT -->
        <div id="chat-viewport" class="flex-1 overflow-y-auto custom-scroll flex flex-col items-center px-4">
            <div id="hero" class="mt-32 text-center transition-all duration-700 select-none">
                <div class="w-24 h-24 mx-auto mb-6 rounded-3xl bg-gradient-to-r from-purple-600 to-pink-600 flex items-center justify-center shadow-2xl">
                    <span class="text-5xl text-white">T</span>
                </div>
                <h1 class="text-5xl font-bold bg-gradient-to-r from-purple-400 to-pink-400 bg-clip-text text-transparent">TYAZA</h1>
                <p class="text-gray-500 mt-3 text-lg">Your therapeutic companion  here to listen</p>
                <p class="text-gray-700 text-sm mt-8 max-w-md mx-auto">"I'm here for you. Take your time, breathe, and share what's on your mind."</p>
            </div>
            
            <!-- Message container - FULL WIDTH for AI responses -->
            <div id="message-container" class="w-full max-w-4xl px-2 pb-32 pt-8 space-y-6 ai-response-full"></div>
            <div id="scroll-anchor" class="h-10"></div>
        </div>

        <!-- INPUT BAR -->
        <div class="w-full max-w-4xl mx-auto px-4 pb-6 absolute bottom-0 left-0 right-0 z-20 bg-gradient-to-t from-[#0a0a0c] via-[#0a0a0c]/95 to-transparent pt-10">
            <div class="bg-[#16161c] rounded-[30px] p-1.5 flex items-end shadow-2xl border border-purple-500/20">
                <!-- Voice Input Button -->
                <button id="voice-input-btn" class="voice-btn h-14 w-14 rounded-full flex items-center justify-center text-gray-400 hover:text-purple-400 transition-all mr-1" title="Click to speak">
                    <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M12 2v12M12 19v3M9 21h6M4 12h2M18 12h2"/>
                        <circle cx="12" cy="12" r="8" stroke="currentColor" fill="none"/>
                    </svg>
                </button>
                
                <textarea id="user-input" rows="1" placeholder="Share your thoughts here..." class="bg-transparent border-none outline-none w-full text-[16px] py-4 px-3 resize-none custom-scroll max-h-32 placeholder:text-gray-600 therapy-spacing"></textarea>
                
                <button id="send-btn" class="h-14 w-14 rounded-full flex items-center justify-center bg-gradient-to-r from-purple-600 to-pink-600 text-white shadow-lg disabled:opacity-30 disabled:from-gray-600 disabled:to-gray-600 transition-all hover:scale-105 mr-1" disabled>
                    <svg width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2.2"><path d="M22 2L11 13M22 2l-7 20-4-9-9-4 20-7z"/></svg>
                </button>
            </div>
            
            <!-- Voice Status with Wave Animation -->
            <div id="voice-status" class="text-center text-sm text-purple-400 mt-3 h-6 flex items-center justify-center gap-2"></div>
            <p class="text-center text-xs text-gray-700 mt-2">TYAZA listens with empathy  concise by default, deep when you need</p>
        </div>
    </main>

    <script>
        (function() {
            // DOM elements
            const container = document.getElementById('message-container');
            const viewport = document.getElementById('chat-viewport');
            const input = document.getElementById('user-input');
            const btn = document.getElementById('send-btn');
            const historyDiv = document.getElementById('history-list');
            const hero = document.getElementById('hero');
            const apiKeyInput = document.getElementById('api-key-input');
            const voiceBtn = document.getElementById('voice-input-btn');
            const voiceStatus = document.getElementById('voice-status');
            const voiceSelect = document.getElementById('voice-select');
            const autoTTS = document.getElementById('auto-tts');
            const testMicBtn = document.getElementById('test-mic-btn');
            const micLed = document.getElementById('mic-led');
            const micStatusText = document.getElementById('mic-status-text');
            const clearHistoryBtn = document.getElementById('clear-history-btn');
            const scrollBottomBtn = document.getElementById('scroll-bottom-btn');
            const voiceWave = document.getElementById('voice-wave');

            // State
            let currentChat = [];
            let isGenerating = false;
            let recognition = null;
            let isListening = false;
            let synth = window.speechSynthesis;
            let micPermission = false;
            let micStream = null;
            let currentChatId = Date.now();
            let isAtBottom = true;
            let audioContext = null;
            let analyser = null;
            let microphone = null;
            let javascriptNode = null;

            // Load API key
            const savedKey = localStorage.getItem('tyaza_therapy_key');
            if (savedKey) apiKeyInput.value = savedKey;

            apiKeyInput.addEventListener('input', function() {
                if (this.value.startsWith('sk-or-v1-')) {
                    localStorage.setItem('tyaza_therapy_key', this.value);
                }
            });

            // Scroll detection
            viewport.addEventListener('scroll', () => {
                const scrollPosition = viewport.scrollTop + viewport.clientHeight;
                const scrollHeight = viewport.scrollHeight;
                isAtBottom = scrollHeight - scrollPosition < 150;
                scrollBottomBtn.classList.toggle('visible', !isAtBottom);
            });

            window.scrollToBottom = () => {
                viewport.scrollTo({ top: viewport.scrollHeight, behavior: 'smooth' });
            };

            // Initialize audio visualization
            async function initAudioVisualization(stream) {
                try {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    analyser = audioContext.createAnalyser();
                    microphone = audioContext.createMediaStreamSource(stream);
                    javascriptNode = audioContext.createScriptProcessor(256, 1, 1);
                    
                    analyser.smoothingTimeConstant = 0.8;
                    analyser.fftSize = 512;
                    
                    microphone.connect(analyser);
                    analyser.connect(javascriptNode);
                    javascriptNode.connect(audioContext.destination);
                    
                    const dataArray = new Uint8Array(analyser.frequencyBinCount);
                    
                    javascriptNode.onaudioprocess = () => {
                        if (!isListening) return;
                        
                        analyser.getByteFrequencyData(dataArray);
                        const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
                        
                        // Update wave visualization
                        const waveBars = voiceWave?.querySelectorAll('span');
                        if (waveBars) {
                            const intensity = average / 128;
                            waveBars.forEach((bar, i) => {
                                bar.style.height = `${5 + (intensity * 25 * (i + 1) / 5)}px`;
                            });
                        }
                    };
                } catch (e) {
                    console.log('Audio visualization not supported');
                }
            }

            // Request microphone with visualization
            async function requestMicrophonePermission() {
                try {
                    if (micStream) {
                        micStream.getTracks().forEach(track => track.stop());
                    }
                    
                    micStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true
                        } 
                    });
                    
                    micPermission = true;
                    micLed.className = 'w-2.5 h-2.5 rounded-full bg-green-500 animate-pulse';
                    micStatusText.textContent = 'Microphone ready  speak anytime';
                    
                    voiceBtn.classList.remove('text-gray-400');
                    voiceBtn.classList.add('text-green-400');
                    
                    // Initialize visualization
                    voiceWave.classList.remove('hidden');
                    voiceWave.classList.add('flex');
                    await initAudioVisualization(micStream);
                    
                    initSpeechRecognition();
                    
                    voiceStatus.innerHTML = '<span class="text-green-400">? Microphone ready for therapy session</span>';
                    setTimeout(() => voiceStatus.innerHTML = '', 3000);
                    
                    return true;
                } catch (error) {
                    micPermission = false;
                    micLed.className = 'w-2.5 h-2.5 rounded-full bg-red-500';
                    micStatusText.textContent = 'Please allow microphone access';
                    voiceWave.classList.add('hidden');
                    voiceStatus.innerHTML = '<span class="text-red-400">? Microphone access needed for voice therapy</span>';
                    return false;
                }
            }

            // Initialize speech recognition with better quality
            function initSpeechRecognition() {
                if (!('webkitSpeechRecognition' in window)) {
                    voiceStatus.innerHTML = '<span class="text-red-400">? Please use Chrome for voice therapy</span>';
                    return false;
                }

                recognition = new webkitSpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = true;
                recognition.maxAlternatives = 1;
                recognition.lang = 'en-US';
                
                // Better noise handling
                recognition.continuous = false;
                recognition.interimResults = true;

                recognition.onstart = () => {
                    isListening = true;
                    voiceBtn.classList.add('listening');
                    voiceStatus.innerHTML = `
                        <div class="flex items-center gap-2">
                            <span class="wave-animation">
                                <span></span><span></span><span></span><span></span><span></span>
                            </span>
                            <span class="text-pink-400">Listening with empathy...</span>
                        </div>`;
                    micLed.className = 'w-2.5 h-2.5 rounded-full bg-red-500 animate-pulse';
                };

                recognition.onend = () => {
                    isListening = false;
                    voiceBtn.classList.remove('listening');
                    voiceStatus.innerHTML = '';
                    micLed.className = 'w-2.5 h-2.5 rounded-full bg-green-500';
                    
                    // Auto-send if there's text
                    if (input.value.trim()) {
                        sendMessage();
                    }
                };

                recognition.onresult = (event) => {
                    let transcript = '';
                    for (let i = 0; i < event.results.length; i++) {
                        transcript += event.results[i][0].transcript;
                    }
                    
                    input.value = transcript;
                    input.style.height = 'auto';
                    input.style.height = Math.min(input.scrollHeight, 128) + 'px';
                    
                    if (transcript.trim()) {
                        btn.disabled = false;
                    }
                    
                    // Show confidence
                    const confidence = event.results[0][0].confidence;
                    if (confidence < 0.7 && event.results[0].isFinal) {
                        voiceStatus.innerHTML = '<span class="text-yellow-400">?? Could you repeat that more clearly?</span>';
                    }
                };

                recognition.onerror = (event) => {
                    let message = '';
                    switch(event.error) {
                        case 'no-speech': message = 'No speech detected. Try again.'; break;
                        case 'audio-capture': message = 'Microphone not working.'; break;
                        case 'not-allowed': message = 'Please allow microphone access.'; break;
                        default: message = `Error: ${event.error}`;
                    }
                    voiceStatus.innerHTML = `<span class="text-red-400">? ${message}</span>`;
                    isListening = false;
                    voiceBtn.classList.remove('listening');
                    micLed.className = 'w-2.5 h-2.5 rounded-full bg-green-500';
                    
                    setTimeout(() => voiceStatus.innerHTML = '', 3000);
                };

                return true;
            }

            // Test mic button
            testMicBtn.addEventListener('click', async (e) => {
                e.preventDefault();
                testMicBtn.innerHTML = '<span>?</span> Requesting...';
                testMicBtn.disabled = true;
                
                const success = await requestMicrophonePermission();
                
                testMicBtn.innerHTML = success ? '<span>?</span> Microphone Ready' : '<span>?</span> Try Again';
                setTimeout(() => {
                    testMicBtn.innerHTML = '<span>??</span> Test Microphone';
                    testMicBtn.disabled = false;
                }, 2000);
            });

            // Voice input button
            voiceBtn.addEventListener('click', async () => {
                if (!('webkitSpeechRecognition' in window)) {
                    alert('Voice therapy works best in Chrome browser');
                    return;
                }
                
                if (!micPermission) {
                    voiceStatus.innerHTML = '<span class="text-yellow-400">? Setting up microphone...</span>';
                    const granted = await requestMicrophonePermission();
                    if (!granted) return;
                }
                
                if (!recognition) {
                    initSpeechRecognition();
                }
                
                if (isListening) {
                    recognition.stop();
                } else {
                    try {
                        recognition.start();
                    } catch (error) {
                        // Reinitialize if needed
                        initSpeechRecognition();
                        setTimeout(() => recognition.start(), 100);
                    }
                }
            });

            // High-quality TTS with therapy-optimized voice
            function speakText(text) {
                if (!synth || !autoTTS.checked) return;
                
                synth.cancel();
                
                // Clean text for speech
                const cleanText = text
                    .replace(/```[\s\S]*?```/g, '')
                    .replace(/`([^`]+)`/g, '$1')
                    .replace(/#{1,6}\s?/g, '')
                    .replace(/[*_~]/g, '')
                    .substring(0, 400);
                
                const utterance = new SpeechSynthesisUtterance(cleanText);
                
                // Get voices and select best therapy voice
                const voices = synth.getVoices();
                const preferredVoice = voiceSelect.value;
                
                // Try to find a warm, therapeutic voice
                utterance.voice = voices.find(v => v.name === preferredVoice) || 
                                 voices.find(v => v.name.includes('Female') && v.lang.includes('en')) ||
                                 voices.find(v => v.lang.includes('en')) || 
                                 voices[0];
                
                // Therapy-optimized settings
                utterance.rate = 0.9;      // Slightly slower for therapy
                utterance.pitch = 1.1;      // Slightly higher, more caring
                utterance.volume = 1;
                
                // Add emotion markers in speech
                utterance.onstart = () => {
                    console.log('Speaking with therapeutic voice');
                };
                
                synth.speak(utterance);
            }

            // Load voices
            if (synth) {
                synth.onvoiceschanged = () => {
                    const voices = synth.getVoices();
                    console.log('Voices loaded for therapy:', voices.length);
                };
            }

            // Escape HTML
            function escapeHtml(text) {
                return text.replace(/[&<>]/g, c => ({ '&': '&amp;', '<': '&lt;', '>': '&gt;' })[c]);
            }

            // Format response with therapy styling
            function formatResponse(text) {
                if (!text) return '';
                
                // Highlight empathy words
                let formatted = escapeHtml(text);
                const empathyWords = ['understand', 'feel', 'emotion', 'hear', 'there for you', 'safe', 'comfort', 'support'];
                empathyWords.forEach(word => {
                    const regex = new RegExp(`\\b(${word})\\b`, 'gi');
                    formatted = formatted.replace(regex, '<span class="empathy-word">$1</span>');
                });
                
                formatted = formatted.replace(/```([\s\S]*?)```/g, '<pre class="bg-black/30 p-4 rounded-xl my-3">$1</pre>');
                formatted = formatted.replace(/`([^`]+)`/g, '<code class="bg-black/30 px-2 py-1 rounded">$1</code>');
                formatted = formatted.replace(/\n\n/g, '<br><br>');
                
                return `<div class="markdown-style therapy-spacing">${formatted}</div>`;
            }

            // Typing effect for AI responses
            async function typeResponse(element, text, speed = 20) {
                const words = text.split(' ');
                element.innerHTML = '';
                
                for (let i = 0; i < words.length; i++) {
                    element.innerHTML += (i === 0 ? '' : ' ') + words[i];
                    if (i < words.length - 1) {
                        element.innerHTML += ' <span class="typing-cursor"></span>';
                    }
                    await new Promise(resolve => setTimeout(resolve, speed));
                }
                
                // Final formatting
                element.innerHTML = formatResponse(text);
            }

            // History functions
            function saveToHistory(firstPrompt) {
                if (!firstPrompt || currentChat.length === 0) return;
                
                const history = JSON.parse(localStorage.getItem('tyaza_therapy_chats') || '[]');
                const existing = history.findIndex(c => c.id === currentChatId);
                const entry = {
                    id: currentChatId,
                    title: firstPrompt.slice(0, 35),
                    messages: currentChat.slice(-30),
                    timestamp: Date.now(),
                    preview: currentChat[currentChat.length-1]?.content.slice(0, 40)
                };
                
                if (existing !== -1) history[existing] = entry;
                else history.unshift(entry);
                
                localStorage.setItem('tyaza_therapy_chats', JSON.stringify(history.slice(0, 20)));
                loadHistoryList();
            }

            function loadHistoryList() {
                const history = JSON.parse(localStorage.getItem('tyaza_therapy_chats') || '[]');
                
                historyDiv.innerHTML = history.length ? history.map((c, i) => {
                    const date = new Date(c.timestamp).toLocaleDateString([], { month: 'short', day: 'numeric' });
                    return `
                        <div class="history-item ${c.id === currentChatId ? 'active' : ''}" onclick="restoreChat(${i})">
                            <div class="font-medium text-sm">${escapeHtml(c.title)}</div>
                            <div class="flex justify-between items-center mt-1">
                                <span class="text-[10px] text-gray-500">${date}</span>
                                <span class="text-[10px] text-purple-400/70">${c.preview ? '?' : ''}</span>
                            </div>
                        </div>
                    `;
                }).join('') : '<div class="text-gray-600 text-sm px-3 py-4 text-center">? No past sessions<br><span class="text-xs">Start a new conversation</span></div>';
            }

            window.restoreChat = function(index) {
                const history = JSON.parse(localStorage.getItem('tyaza_therapy_chats') || '[]');
                const chat = history[index];
                if (!chat) return;
                
                currentChatId = chat.id;
                hero.style.display = 'none';
                container.innerHTML = '';
                currentChat = [];
                
                chat.messages.forEach(msg => {
                    const div = document.createElement('div');
                    div.className = 'message-enter w-full';
                    
                    if (msg.role === 'user') {
                        div.innerHTML = `<div class="flex justify-end"><div class="chat-bubble-user">${escapeHtml(msg.content)}</div></div>`;
                    } else {
                        div.innerHTML = `
                            <div class="flex gap-4 w-full">
                                <div class="ai-avatar flex-shrink-0 mt-1"></div>
                                <div class="flex-1 chat-bubble-ai">${formatResponse(msg.content)}</div>
                            </div>`;
                    }
                    container.appendChild(div);
                });
                
                currentChat = chat.messages;
                loadHistoryList();
                scrollToBottom();
            };

            window.startNewChat = () => {
                container.innerHTML = '';
                hero.style.display = 'block';
                currentChat = [];
                currentChatId = Date.now();
                input.value = '';
                btn.disabled = true;
                loadHistoryList();
                scrollToBottom();
            };

            clearHistoryBtn.onclick = () => {
                if (confirm('Clear all therapy sessions?')) {
                    localStorage.removeItem('tyaza_therapy_chats');
                    startNewChat();
                }
            };

            // Send message with typing effect
            async function sendMessage() {
                const text = input.value.trim();
                if (!text || isGenerating) return;

                const apiKey = apiKeyInput.value.trim();
                if (!apiKey?.startsWith('sk-or-v1-')) {
                    alert('Please enter your OpenRouter key for therapy sessions');
                    return;
                }

                hero.style.display = 'none';
                
                // User message
                container.innerHTML += `<div class="message-enter flex justify-end w-full"><div class="chat-bubble-user">${escapeHtml(text)}</div></div>`;
                
                // AI thinking with animation
                const aiId = 'msg-' + Date.now();
                container.innerHTML += `
                    <div class="message-enter flex gap-4 w-full" id="wrapper-${aiId}">
                        <div class="ai-avatar thinking"></div>
                        <div class="flex-1 chat-bubble-ai" id="${aiId}">
                            <div class="typing-animation">
                                <span></span><span></span><span></span>
                                <span class="text-gray-500 ml-2 text-sm">TYAZA is listening...</span>
                            </div>
                        </div>
                    </div>`;
                
                scrollToBottom();
                
                currentChat.push({ role: 'user', content: text });
                input.value = '';
                btn.disabled = true;
                isGenerating = true;

                try {
                    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
                        method: "POST",
                        headers: {
                            "Authorization": `Bearer ${apiKey}`,
                            "Content-Type": "application/json",
                            "HTTP-Referer": window.location.origin,
                            "X-Title": "TYAZA Therapy AI"
                        },
                        body: JSON.stringify({
                            "model": "openrouter/free",
                            "messages": [
                                { 
                                    "role": "system", 
                                    "content": `You are TYAZA, a compassionate therapeutic AI assistant. 
                                    Guidelines:
                                    - Respond with warmth, empathy, and genuine care
                                    - Keep responses concise (2-4 sentences) unless user asks for more
                                    - Use gentle, supportive language
                                    - Acknowledge feelings and validate experiences
                                    - Never be clinical or robotic
                                    - Offer hope and comfort
                                    - If user seems distressed, respond with extra care
                                    - Use phrases like "I hear you", "that sounds difficult", "you're not alone"
                                    - Be present and attentive in your responses`
                                },
                                ...currentChat.map(m => ({ role: m.role, content: m.content }))
                            ],
                            "max_tokens": 500,
                            "temperature": 0.8
                        })
                    });

                    if (!response.ok) throw new Error('Unable to connect. Please try again.');
                    
                    const data = await response.json();
                    const answer = data.choices?.[0]?.message?.content || "I'm here for you. Could you tell me more about what's on your mind?";
                    
                    // Type the response
                    const aiEl = document.getElementById(aiId);
                    await typeResponse(aiEl, answer, 15);
                    
                    // Remove thinking class
                    document.querySelector(`#wrapper-${aiId} .ai-avatar`).classList.remove('thinking');
                    
                    // Speak if enabled
                    if (autoTTS.checked) {
                        setTimeout(() => speakText(answer), 100);
                    }
                    
                    currentChat.push({ role: 'assistant', content: answer });
                    
                    if (currentChat.length === 2) saveToHistory(text);

                } catch (error) {
                    const aiEl = document.getElementById(aiId);
                    aiEl.innerHTML = `<span class="text-red-400">I'm having trouble connecting. Please check your connection and try again.</span>`;
                    document.querySelector(`#wrapper-${aiId} .ai-avatar`).classList.remove('thinking');
                } finally {
                    isGenerating = false;
                }
            }

            // Input handlers
            input.oninput = function() {
                this.style.height = 'auto';
                this.style.height = Math.min(this.scrollHeight, 128) + 'px';
                btn.disabled = !this.value.trim() || isGenerating;
            };

            btn.onclick = sendMessage;
            input.onkeydown = (e) => {
                if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    !btn.disabled && sendMessage();
                }
            };

            // Initialize
            window.onload = () => {
                loadHistoryList();
                startNewChat();
                
                // Pre-load voices
                if (synth) {
                    synth.getVoices();
                }
            };
        })();
    </script>
</body>
</html>